# 03 Model Training and Improvement

## Стъпки за лабораторно упражнение
Portuguese bank dataset
1. Четене.
2. Обработка:
	1. Разделяне на feature и target променливи.
	2. Заменяне на класовете (анотациите) с 0 и 1.
	3. Проверка, че размерите на групите са коректни.
3. Добавяне на индикаторни променливи за всички категориини колони.
4. Разделяне на обучителни и тестови множества.
5. Oбучение на първоначален алгоритъм (логистична регресия).
	1. Оценка на модела с метрика accuracy.
6. Оценка на представянето на модела с друга, по-добра, метрика - f1 score.
7. Настройване на хипер параметрите на модела (grid search).

## L1 vs L2 regularization


Капацитет на модел = statistical power

възможността на една хипотеза да опише данните добре

в случая с модели - възможността модела да опише данните

модела има капацитет

целта на МЛ не е да опише наличните данни най-добре, а да опишем по-добре бъдещи данни

да обосновеш всяка стъпка

## Регуляризация на модела

## Regularization

Модел учи от данните ако с времето подобрява някаква метрика

контролна проба

## ## Bias Variance Tradeoff

един модел има low/high bias/variance

variance = нестабилност; доколко хаотичен е модела

bias = грешка при предположенията, при висок bias се целим на грешно място

При d=6 данните (точките) са описани почти перфектно, със сигърно по-добре от d=2. Само че д=6 не може да предкаже, не описва нови точки.

Очакването каква да е формата на модела идва напр от бизнес съображения, но няма как да дойде от модела.

д=2 е най-добрата парабола през точките, но дали парабола е най-добрия модел?

over-fitting - твърде много го е грижа за данните, има голяма мощ (predictive power), описал е наблюдаваните данните перфектно, но не генерализира добре за нови данни

under-fitting = твърде слаб модел, не описва наблюденията достатъчно добре. Това може да идва от bias данните, модела, типа модел…. Всички тези причини се наричат заедно bias.

Under-fitting се разпознава сравнително лесно -> пробваме друг модел ИЛИ намаляваме бр наблюдения ИЛИ даваме му по-конкретна задача

## ## Регуляризация

деф = да направим модела по-регулярен, по-малко хаотичен

Това са начини за "изглаждане" на моделиращата функция.

идея: намаляване на тегловните коеф. това води до значимостта на променливите на модела.
евклидова норма или евклидово разстояние

Регуляризация - добавяне на единия от двата израза L1 или L2 към cost функцията

ако клас 1 >> клас 2, то клас1 е majority class

Колкото регуляризацията е по-голяма, ткокова  по-гладка е фунцкията

анотация = клас

## Тестване на Модели

стратифицирана случайна извадка - популацията е разделена на категории

Ако една извадка не е случайно избрана, тя вероятно ще има някакво отклонение (изместване) sampling bias и данните може да не са представителни за генералната съвкупност

При разделяне на данните на трениращи модели и тестващи модела, двете групи трябва имат енаква пропорция на класовете (Output-ите), да са стратифицирани извадки.

## ## Метрики

R^2 коеф на определеност

стандартната (default-ната) метрика за Лин Рег

добре е да е високо число

Модел, който винаги предсказва средното аритметично на всички изходи има R2 = 0

По-лош модел -> R2 < 0

precision е мярка за Класификация

residual - разликата между наблюдавано и предсказано = y_tilda - y

accuracy paradox = висока стойност на accuracy при силно небалансирани класове

F1-score = средно хармонично на precision and recall

защо "1" след F-а?

ROC - визуална техника за оценка класификация

ако кривата е под 0,0 1,1 линията означава че моделът обръща класовете - казва positive когато е negative

хипер параметър = настойка на модела

validation set / development set - част от данните, върху който итерираме модели с различни хипер параметри. Чак след като сме избрали най-подходящия модел, проверяваме с тестовите данни.